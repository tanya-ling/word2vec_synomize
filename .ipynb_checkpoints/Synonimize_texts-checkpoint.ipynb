{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine two texts changing words to quasisinonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tatiana\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = ## YOUR WORKING DIRECTIRY HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load sample files in docs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def getText(filename1, filename2):\n",
    "    doc1 = docx.Document(filename1)\n",
    "    doc2 = docx.Document(filename2)\n",
    "    para1 = doc1.paragraphs\n",
    "    para2 = doc2.paragraphs\n",
    "    para1 = [p for p in para1 if p.text!='']\n",
    "    para2 = [p for p in para2 if p.text!='']\n",
    "    fullText = []\n",
    "    j = 0\n",
    "    k = 0\n",
    "    for i in range(len(para1) + len(para2)):\n",
    "        if i % 2 == 0:\n",
    "            try:\n",
    "                fullText.append(para1[j].text)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            j += 1\n",
    "        else:\n",
    "            try:\n",
    "                fullText.append(para2[k].text)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            k += 1\n",
    "    return '\\n'.join(fullText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "punct = re.compile('^(.*?)([а-яА-ЯёЁ-]+)(.*?)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "capit_letters = [chr(x) for x in range(1040,1072)] + ['Ё']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_neighbour(word, pos, gend='masc'):\n",
    "    word = word.replace('ё', 'е')\n",
    "    lex = word + '_' + cotags[pos]\n",
    "    if lex in model:\n",
    "        neighbs = model.most_similar([lex], topn=20)\n",
    "        for nei in neighbs:\n",
    "            lex_n, ps_n = nei[0].split('_')\n",
    "            if '::' in lex_n:\n",
    "                continue\n",
    "            if cotags[pos] == ps_n:\n",
    "                if pos == 'NOUN':\n",
    "                    parse_result = morph.parse(lex_n)\n",
    "                    for ana in parse_result:\n",
    "                        if ana.normal_form == lex_n:\n",
    "                            if ana.tag.gender == gend:\n",
    "                                return lex_n\n",
    "                elif cotags[pos] == 'VERB' and word[-2:] == 'ся':\n",
    "                    if lex_n[-2:] == 'ся':\n",
    "                        return lex_n\n",
    "                elif cotags[pos] == 'VERB' and word[-2:] != 'ся':\n",
    "                    if lex_n[-2:] != 'ся':\n",
    "                        return lex_n\n",
    "                else:\n",
    "                    return lex_n\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flection(lex_neighb, tags):\n",
    "    tags = str(tags)\n",
    "    tags = re.sub(',[AGQSPMa-z-]+? ', ',', tags)\n",
    "    tags = tags.replace(\"impf,\", \"\")\n",
    "    tags = re.sub('([A-Z]) (plur|masc|femn|neut|inan)', '\\\\1,\\\\2', tags)\n",
    "    tags = tags.replace(\"Impe neut\", \"\")\n",
    "    tags = tags.split(',')\n",
    "    tags_clean = []\n",
    "    for t in tags:\n",
    "        if t:\n",
    "            if ' ' in t:\n",
    "                t1, t2 = t.split(' ')\n",
    "                t = t2\n",
    "            tags_clean.append(t)\n",
    "    tags = frozenset(tags_clean)\n",
    "    prep_for_gen = morph.parse(lex_neighb)\n",
    "    ana_array = []\n",
    "    for ana in prep_for_gen:\n",
    "        if ana.normal_form == lex_neighb:\n",
    "            ana_array.append(ana)\n",
    "    for ana in ana_array:\n",
    "        try:\n",
    "            flect = ana.inflect(tags)\n",
    "        except:\n",
    "            print(tags)\n",
    "            return None\n",
    "        if flect:\n",
    "            word_to_replace = flect.word\n",
    "            return word_to_replace\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# начинается ли слово с большой буквы?\n",
    "capit = re.compile('^[А-Я]+$')\n",
    "def capit_flagging(wordform):\n",
    "    if wordform[0] in capit_letters: \n",
    "                        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ищем ближайшие слова в модели, для существительных учитываем род\n",
    "def find_neighb(pos_tag, parse_results, lex, parse_result):\n",
    "    if pos_tag == 'NOUN':\n",
    "        gen_tag = parse_result.tag.gender\n",
    "        lex_neighb = search_neighbour(lex, pos_tag, gend=gen_tag)\n",
    "    else:\n",
    "        lex_neighb = search_neighbour(lex, pos_tag)\n",
    "    return lex_neighb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ищем соседа и кэшируем, если он еще не кэширован\n",
    "def find_if_not_cashed(lex, pos_tag, cash_neighb, parse_results):\n",
    "    if (lex, pos_tag) in cash_neighb:\n",
    "        lex_neighb = cash_neighb[(lex, pos_tag)]\n",
    "    else:\n",
    "        lex_neighb = find_neighb(pos_tag, parse_results, lex, parse_results) # ищем ближайший квазисиноним\n",
    "        cash_neighb[(lex, pos_tag)] = lex_neighb # запомнили его на будущее\n",
    "    return lex_neighb, cash_neighb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put noun in the right form\n",
    "def nouns(parse_result, capit_flag, lex_neighb, struct, word):\n",
    "    if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "        if capit_flag == 1:\n",
    "            lex_neighb = lex_neighb.capitalize()\n",
    "        return struct[0] + lex_neighb + struct[2]\n",
    "    else:\n",
    "        word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "        if word_to_replace:\n",
    "            if capit_flag == 1:\n",
    "                word_to_replace = word_to_replace.capitalize()\n",
    "            return struct[0] + word_to_replace + struct[2]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put adjectives in the right form\n",
    "def adjectives(parse_result, capit_flag, lex_neighb, struct, word):\n",
    "    if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing' and parse_result.tag.gender == 'masc': \n",
    "        if capit_flag == 1:\n",
    "            lex_neighb = lex_neighb.capitalize()\n",
    "        return struct[0] + lex_neighb + struct[2]\n",
    "    else:\n",
    "        word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "        if word_to_replace:\n",
    "            if capit_flag == 1:\n",
    "                word_to_replace = word_to_replace.capitalize()\n",
    "            return struct[0] + word_to_replace + struct[2]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put a word in the right form\n",
    "def put_in_the_right_form(pos_tag, parse_result, capit_flag, lex_neighb, struct, word):\n",
    "    if pos_tag == 'NOUN':\n",
    "        return nouns(parse_result, capit_flag, lex_neighb, struct, word)                         \n",
    "    elif pos_tag == 'ADJF':\n",
    "        return adjectives(parse_result, capit_flag, lex_neighb, struct, word)                        \n",
    "    elif pos_tag == 'INFN':\n",
    "        if capit_flag == 1:\n",
    "            lex_neighb = lex_neighb.capitalize()\n",
    "        return struct[0] + lex_neighb + struct[2]                         \n",
    "    elif pos_tag in ['ADVB', 'COMP', 'PRED']:\n",
    "        if capit_flag == 1:\n",
    "            lex_neighb = lex_neighb.capitalize()\n",
    "        return struct[0] + lex_neighb + struct[2]    \n",
    "    else:\n",
    "        word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "        if word_to_replace:\n",
    "            if capit_flag == 1:\n",
    "                word_to_replace = word_to_replace.capitalize()\n",
    "            return struct[0] + word_to_replace + struct[2]\n",
    "        else:\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_text(line):\n",
    "    cash_neighb = {}\n",
    "    new_line = []\n",
    "    line = text_example.strip()\n",
    "    words = line.split(' ')\n",
    "    for word in words:\n",
    "        struct = punct.findall(word)\n",
    "        if struct:\n",
    "            struct = struct[0]\n",
    "        else:\n",
    "            new_line.append(word)\n",
    "            continue\n",
    "        wordform = struct[1]\n",
    "        if wordform:\n",
    "            if capit.search(wordform): # аббревиатуры (все буквы большие) не меняем\n",
    "                new_line.append(word)\n",
    "                continue            \n",
    "            capit_flag = capit_flagging(wordform) # начинается ли слово с большой буквы?\n",
    "            parse_result = morph.parse(wordform)[0]\n",
    "            \n",
    "            if 'Name' in parse_result.tag or 'Patr' in parse_result.tag: # Не меняем личные имена и названия мест\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                        \n",
    "            pos_flag = 0\n",
    "            for tg in cotags:\n",
    "                if tg in parse_result.tag:\n",
    "                    pos_flag = 1\n",
    "                    lex = parse_result.normal_form\n",
    "                    pos_tag = parse_result.tag.POS\n",
    "                    lex_neighb, cash_neighb = find_if_not_cashed(lex, pos_tag, cash_neighb, parse_result)\n",
    "                    if not lex_neighb: # если к слову нет синонимов, не меняем его\n",
    "                        new_line.append(word)\n",
    "                        break\n",
    "                    else: # Иначе нам нужно поставить его в правильную форму\n",
    "                        to_append = put_in_the_right_form(pos_tag, parse_result, capit_flag, lex_neighb, struct, word)\n",
    "                        new_line.append(to_append)\n",
    "                        break\n",
    "            if pos_flag == 0:\n",
    "                new_line.append(word)\n",
    "        else:\n",
    "            new_line.append(''.join(struct))\n",
    "        line_replace = ' '.join(new_line)\n",
    "    return line_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Load pretrained word2vec model and transform text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rusvectores model trained on 600 millions words (wiki+ruscorpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = directory + '/models/ruwikiruscorpora_0_300_20.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if the model is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('гг_NOUN', 0.6715219020843506),\n",
       " ('официально_ADV', 0.5154324769973755),\n",
       " ('месяц_NOUN', 0.4920658469200134),\n",
       " ('ранее_ADV', 0.4650496542453766),\n",
       " ('впоследствии_ADV', 0.46287965774536133),\n",
       " ('период_NOUN', 0.4466725289821625),\n",
       " ('вскоре_ADV', 0.428223192691803),\n",
       " ('великобритания_NOUN', 0.4216790795326233),\n",
       " ('руководство_NOUN', 0.4185072183609009),\n",
       " ('незадолго_ADV', 0.41545569896698),\n",
       " ('поздно_ADV', 0.4105498194694519),\n",
       " ('совместно_ADV', 0.40229037404060364),\n",
       " ('первоначально_ADV', 0.40022385120391846),\n",
       " ('го_NOUN', 0.3999163508415222),\n",
       " ('полгода_NOUN', 0.3921680450439453),\n",
       " ('санкт-петербург_NOUN', 0.3864089250564575),\n",
       " ('ежегодно_ADV', 0.3858228325843811),\n",
       " ('нидерланды_NOUN', 0.3828669786453247),\n",
       " ('ганновер_NOUN', 0.3802339434623718),\n",
       " ('фактически_ADV', 0.3796970546245575)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['год_NOUN'], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretrained model has other morphological tags, need to transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cotags = {'ADJF':'ADJ', # pymorphy2: word2vec \n",
    "'ADJS' : 'ADJ', \n",
    "'ADVB' : 'ADV', \n",
    "'COMP' : 'ADV', \n",
    "'GRND' : 'VERB', \n",
    "'INFN' : 'VERB', \n",
    "'NOUN' : 'NOUN', \n",
    "'PRED' : 'ADV', \n",
    "'PRTF' : 'ADJ', \n",
    "'PRTS' : 'VERB', \n",
    "'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load texts and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "docnames = ['Педагогика', 'Кадровое делопроизводство', 'Строительство', 'Транспорт', 'Маркшейдерия']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for docname in docnames:\n",
    "    path1 = directory + '/SampleTexts' + '/' + docname +'1.docx'\n",
    "    path2 = directory + '/SampleTexts' + '/' + docname +'2.docx'\n",
    "\n",
    "    text_example = getText(path1, path2)\n",
    "    new_text = transform_text(text_example)\n",
    "    path = directory + '/results/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    document = docx.Document()\n",
    "    p = document.add_paragraph(new_text)\n",
    "    document.save(path + 'wiki_' + docname + '.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# our model trained on ~ 600 thousands of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cotags = {'ADJF':'ADJF', # pymorphy2: pymorphy2 \n",
    "'ADJS' : 'ADJS', \n",
    "'ADVB' : 'ADVB', \n",
    "'COMP' : 'COMP', \n",
    "'GRND' : 'GRND', \n",
    "'INFN' : 'INFN', \n",
    "'NOUN' : 'NOUN', \n",
    "'PRED' : 'PRED', \n",
    "'PRTF' : 'PRTF', \n",
    "'PRTS' : 'PRTS', \n",
    "'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = directory + '/models/mymodel.bin'\n",
    "model = gensim.models.Word2Vec.load(path)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "check if the model is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('пять_NUMR', 0.8945003747940063),\n",
       " ('раз_NOUN', 0.8592861890792847),\n",
       " ('реж_NOUN', 0.8405357599258423),\n",
       " ('согласно_PREP', 0.7899616360664368),\n",
       " ('начальник_NOUN', 0.7609720230102539),\n",
       " ('должность_NOUN', 0.7586870789527893),\n",
       " ('руководящий_ADJF', 0.749430775642395),\n",
       " ('рядовой_ADJF', 0.7473839521408081),\n",
       " ('утвердить_PRTS', 0.7447465658187866),\n",
       " ('появиться_VERB', 0.7317184209823608),\n",
       " ('трудоустройство_NOUN', 0.7218949794769287),\n",
       " ('устраиваться_INFN', 0.7142784595489502),\n",
       " ('законодательно_ADVB', 0.7088960409164429),\n",
       " ('прервать_VERB', 0.7014658451080322),\n",
       " ('руководитель_NOUN', 0.6981256008148193),\n",
       " ('переходить_INFN', 0.6969155073165894),\n",
       " ('врач-гастроэнтеролог_NOUN', 0.6964960694313049),\n",
       " ('проходить_INFN', 0.6951399445533752),\n",
       " ('бухгалтер_NOUN', 0.6890097856521606),\n",
       " ('претендовать_INFN', 0.6848532557487488)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['год_NOUN'], topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load texts and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "docnames = ['Педагогика', 'Кадровое делопроизводство', 'Строительство', 'Транспорт', 'Маркшейдерия']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for docname in docnames:\n",
    "    path1 = directory + '/SampleTexts' + '/' + docname +'1.docx'\n",
    "    path2 = directory + '/SampleTexts' + '/' + docname +'2.docx'\n",
    "\n",
    "    text_example = getText(path1, path2)\n",
    "    new_text = transform_text(text_example)\n",
    "    path = directory + '/results/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    document = docx.Document()\n",
    "    p = document.add_paragraph(new_text)\n",
    "    document.save(path + 'mymodel_' + docname + '.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
